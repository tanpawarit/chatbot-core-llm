#!/usr/bin/env python3
"""
Test Warmup Performance - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á LLM Warmup
‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á warmup
"""

import time
import sys
import os

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.llm.factory import llm_factory
from src.llm.node.nlu_llm import analyze_message_nlu
from src.llm.node.response_llm import generate_response
from src.models import Message, MessageRole
from src.utils.logging import get_logger

logger = get_logger(__name__)

def test_cold_vs_warm_nlu():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö NLU ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á warmup"""
    print("\n" + "="*60)
    print("üß† NLU COLD vs WARM TEST")
    print("="*60)
    
    test_message = "‡∏≠‡∏¢‡∏≤‡∏Å‡∏ã‡∏∑‡πâ‡∏≠‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ñ‡∏£‡∏±‡∏ö"
    
    # Test 1: Cold start (reset factory)
    print("\n‚ùÑÔ∏è Cold Start Test:")
    llm_factory._instances.clear()
    llm_factory._warmup_status.clear()
    
    start_time = time.time()
    try:
        nlu_result = analyze_message_nlu(test_message)
        cold_time = (time.time() - start_time) * 1000
        print(f"  Cold NLU: {cold_time:.1f}ms")
        print(f"  Result: {nlu_result.primary_intent if nlu_result else 'Failed'}")
    except Exception as e:
        cold_time = (time.time() - start_time) * 1000
        print(f"  Cold NLU FAILED: {cold_time:.1f}ms - {str(e)}")
        return
    
    # Test 2: Warm start (after warmup)
    print("\nüî• Warm Start Test:")
    warmup_start = time.time()
    warmup_success = llm_factory.warmup_classification_llm()
    warmup_time = (time.time() - warmup_start) * 1000
    print(f"  Warmup: {warmup_time:.1f}ms ({'‚úÖ' if warmup_success else '‚ùå'})")
    
    start_time = time.time()
    try:
        nlu_result = analyze_message_nlu(test_message)
        warm_time = (time.time() - start_time) * 1000
        print(f"  Warm NLU: {warm_time:.1f}ms")
        print(f"  Result: {nlu_result.primary_intent if nlu_result else 'Failed'}")
    except Exception as e:
        warm_time = (time.time() - start_time) * 1000
        print(f"  Warm NLU FAILED: {warm_time:.1f}ms - {str(e)}")
        return
    
    # Compare results
    improvement = ((cold_time - warm_time) / cold_time) * 100
    print(f"\nüìä Performance Improvement:")
    print(f"  Cold: {cold_time:.1f}ms")  
    print(f"  Warm: {warm_time:.1f}ms")
    print(f"  Improvement: {improvement:.1f}% faster")
    
    return {
        'cold_time': cold_time,
        'warm_time': warm_time,
        'warmup_time': warmup_time,
        'improvement_percent': improvement
    }

def test_cold_vs_warm_response():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Response LLM ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á warmup"""
    print("\n" + "="*60)
    print("ü§ñ RESPONSE LLM COLD vs WARM TEST")
    print("="*60)
    
    test_messages = [Message(role=MessageRole.USER, content="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö")]
    
    # Test 1: Cold start (reset factory)
    print("\n‚ùÑÔ∏è Cold Start Test:")
    llm_factory._instances.clear()
    llm_factory._warmup_status.clear()
    
    start_time = time.time()
    try:
        response = generate_response(test_messages)
        cold_time = (time.time() - start_time) * 1000
        print(f"  Cold Response: {cold_time:.1f}ms")
        print(f"  Result: {response[:50]}..." if len(response) > 50 else f"  Result: {response}")
    except Exception as e:
        cold_time = (time.time() - start_time) * 1000
        print(f"  Cold Response FAILED: {cold_time:.1f}ms - {str(e)}")
        return
    
    # Test 2: Warm start (after warmup)
    print("\nüî• Warm Start Test:")
    warmup_start = time.time()
    warmup_success = llm_factory.warmup_response_llm()
    warmup_time = (time.time() - warmup_start) * 1000
    print(f"  Warmup: {warmup_time:.1f}ms ({'‚úÖ' if warmup_success else '‚ùå'})")
    
    start_time = time.time()
    try:
        response = generate_response(test_messages)
        warm_time = (time.time() - start_time) * 1000
        print(f"  Warm Response: {warm_time:.1f}ms")
        print(f"  Result: {response[:50]}..." if len(response) > 50 else f"  Result: {response}")
    except Exception as e:
        warm_time = (time.time() - start_time) * 1000
        print(f"  Warm Response FAILED: {warm_time:.1f}ms - {str(e)}")
        return
    
    # Compare results
    improvement = ((cold_time - warm_time) / cold_time) * 100
    print(f"\nüìä Performance Improvement:")
    print(f"  Cold: {cold_time:.1f}ms")  
    print(f"  Warm: {warm_time:.1f}ms")
    print(f"  Improvement: {improvement:.1f}% faster")
    
    return {
        'cold_time': cold_time,
        'warm_time': warm_time,
        'warmup_time': warmup_time,
        'improvement_percent': improvement
    }

def test_parallel_warmup():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö parallel warmup"""
    print("\n" + "="*60)
    print("‚ö° PARALLEL WARMUP TEST")
    print("="*60)
    
    # Reset factory
    llm_factory._instances.clear()
    llm_factory._warmup_status.clear()
    
    # Test parallel warmup
    start_time = time.time()
    success = llm_factory.warmup_all_llms()
    total_time = (time.time() - start_time) * 1000
    
    print(f"\nüìä Parallel Warmup Results:")
    print(f"  Total Time: {total_time:.1f}ms")
    print(f"  Success: {'‚úÖ' if success else '‚ùå'}")
    print(f"  Status: {llm_factory.get_warmup_status()}")
    
    return {
        'total_time': total_time,
        'success': success,
        'status': llm_factory.get_warmup_status()
    }

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö warmup"""
    print("üöÄ Starting LLM Warmup Performance Testing...")
    
    results = {}
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö NLU
    try:
        results['nlu'] = test_cold_vs_warm_nlu()
    except Exception as e:
        print(f"‚ùå NLU test failed: {str(e)}")
        results['nlu'] = None
    
    # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà
    time.sleep(2)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Response LLM  
    try:
        results['response'] = test_cold_vs_warm_response()
    except Exception as e:
        print(f"‚ùå Response test failed: {str(e)}")
        results['response'] = None
    
    # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà
    time.sleep(2)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Parallel Warmup
    try:
        results['parallel'] = test_parallel_warmup()
    except Exception as e:
        print(f"‚ùå Parallel warmup test failed: {str(e)}")
        results['parallel'] = None
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°
    print("\n" + "="*80)
    print("üìà WARMUP PERFORMANCE SUMMARY")
    print("="*80)
    
    if results['nlu']:
        print(f"\nüß† NLU Performance:")
        print(f"   Cold Start: {results['nlu']['cold_time']:.1f}ms")
        print(f"   Warm Start: {results['nlu']['warm_time']:.1f}ms")
        print(f"   Improvement: {results['nlu']['improvement_percent']:.1f}% faster")
        print(f"   Warmup Cost: {results['nlu']['warmup_time']:.1f}ms")
    
    if results['response']:
        print(f"\nü§ñ Response LLM Performance:")
        print(f"   Cold Start: {results['response']['cold_time']:.1f}ms")
        print(f"   Warm Start: {results['response']['warm_time']:.1f}ms")
        print(f"   Improvement: {results['response']['improvement_percent']:.1f}% faster")
        print(f"   Warmup Cost: {results['response']['warmup_time']:.1f}ms")
    
    if results['parallel']:
        print(f"\n‚ö° Parallel Warmup:")
        print(f"   Total Time: {results['parallel']['total_time']:.1f}ms")
        print(f"   Success Rate: {'100%' if results['parallel']['success'] else 'Failed'}")
    
    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    print(f"\nüí° Recommendations:")
    
    if results['nlu'] and results['nlu']['improvement_percent'] > 20:
        print(f"   ‚úÖ NLU warmup provides significant improvement ({results['nlu']['improvement_percent']:.1f}%)")
    elif results['nlu']:
        print(f"   ‚ö†Ô∏è  NLU warmup improvement is minimal ({results['nlu']['improvement_percent']:.1f}%)")
    
    if results['response'] and results['response']['improvement_percent'] > 20:
        print(f"   ‚úÖ Response LLM warmup provides significant improvement ({results['response']['improvement_percent']:.1f}%)")
    elif results['response']:
        print(f"   ‚ö†Ô∏è  Response LLM warmup improvement is minimal ({results['response']['improvement_percent']:.1f}%)")
    
    if results['parallel'] and results['parallel']['success']:
        print(f"   ‚úÖ Parallel warmup works well (total: {results['parallel']['total_time']:.1f}ms)")
    elif results['parallel']:
        print(f"   ‚ùå Parallel warmup had issues")
    
    print("\nüéØ Recommended Implementation:")
    print("   1. Run warmup_all_llms() at application startup")
    print("   2. Expected first-response improvement: 20-80% faster")
    print("   3. Warmup cost is one-time per application restart")
    
    print("="*80)
    
    return results

if __name__ == "__main__":
    try:
        results = main()
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Testing interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error during testing: {str(e)}")
        import traceback
        traceback.print_exc()