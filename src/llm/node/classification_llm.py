"""Simple classification LLM node"""

import json
from typing import Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from src.config import config_manager
from src.models import EventClassification
from src.utils.logging import get_logger

logger = get_logger(__name__)


# Event classification prompts and constants
EVENT_CLASSIFICATION_SYSTEM_PROMPT = """<system_identity>
Conversation analysis expert specializing in event classification and importance assessment.
</system_identity>

<event_types>
â€¢ INQUIRY: Questions, inquiries, asking for information
â€¢ FEEDBACK: Reviews, opinions, likes/dislikes, evaluations
â€¢ REQUEST: Requests for services, bookings, wanting something
â€¢ COMPLAINT: Problems, issues, complaints, dissatisfaction
â€¢ TRANSACTION: Buying, paying, pricing, financial matters
â€¢ SUPPORT: Help requests, guidance, how-to questions
â€¢ INFORMATION: Providing information, announcements, notifications
â€¢ GENERIC_EVENT: Greetings, thanks, social interactions
</event_types>

<importance_scale>
â€¢ 0.9-1.0: Transactions, critical issues
â€¢ 0.7-0.8: Important requests, feedback
â€¢ 0.5-0.6: Support requests
â€¢ 0.3-0.4: Simple questions
â€¢ 0.1-0.2: Greetings, social interactions
</importance_scale>

<output_format>
Respond with JSON following EventClassification schema only:
{
  "event_type": "one of the types above",
  "importance_score": 0.0-1.0,
  "intent": "text description of user intent",
  "reasoning": "brief explanation"
}
</output_format>"""

def classify_event(user_message: str) -> Optional[EventClassification]:
    """
    Classify user message into event type and importance using LLM
    
    Args:
        user_message: User's message content
        
    Returns:
        EventClassification object or None if classification fails
    """
    try:
        # Get configuration
        config = config_manager.get_openrouter_config()
        openrouter_config = config_manager.get_openrouter_config()
        
        # Initialize LLM client
        from langchain_core.utils import convert_to_secret_str
        
        llm = ChatOpenAI(
            model=config.classification.model,
            api_key=convert_to_secret_str(openrouter_config.api_key),
            base_url=openrouter_config.base_url,
            temperature=config.classification.temperature,
        ) 
        
        # Prepare messages
        messages = [
            SystemMessage(content=EVENT_CLASSIFICATION_SYSTEM_PROMPT),
            HumanMessage(content=user_message)
        ]
        
        logger.info("Classifying event", 
                   message_length=len(user_message),
                   model=config.classification.model)
        
        # Pretty print Classification LLM Context
        print("\n" + "="*60)
        print("ðŸ¤– Classification LLM Context")
        print("="*60)
        for i, msg in enumerate(messages, 1):
            role = type(msg).__name__.replace("Message", "").upper()
            print(f"{i}. [{role}] {msg.content}")
        print("="*60)
        
        # Get LLM response
        response = llm.invoke(messages)
        
        # Parse JSON response
        response_content = response.content if isinstance(response.content, str) else str(response.content)
        
        # Strip markdown code blocks if present
        cleaned_content = response_content.strip()
        if cleaned_content.startswith('```json'):
            # Remove opening ```json and closing ```
            cleaned_content = cleaned_content[7:]  # Remove ```json
            if cleaned_content.endswith('```'):
                cleaned_content = cleaned_content[:-3]  # Remove closing ```
            cleaned_content = cleaned_content.strip()
        elif cleaned_content.startswith('```'):
            # Remove opening ``` and closing ```
            cleaned_content = cleaned_content[3:]  # Remove opening ```
            if cleaned_content.endswith('```'):
                cleaned_content = cleaned_content[:-3]  # Remove closing ```
            cleaned_content = cleaned_content.strip()
        
        classification_data = json.loads(cleaned_content)
        classification = EventClassification(**classification_data)
        
        logger.info("Event classified", 
                   event_type=classification.event_type,
                   importance_score=classification.importance_score)
        
        return classification
        
    except json.JSONDecodeError as e:
        logger.error("Failed to parse LLM response as JSON", 
                    error=str(e), 
                    response=response.content,
                    cleaned_content=locals().get('cleaned_content', 'not_cleaned'))
        return None
    except Exception as e:
        logger.error("Failed to classify event", error=str(e))
        return None